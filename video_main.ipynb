{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane Detection and Classification using Cascaded CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries and CNN models\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "# Data loading and visualization imports\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from matplotlib.pyplot import imshow, figure, subplots\n",
    "\n",
    "# Model loading\n",
    "from models.erfnet import Net as ERFNet\n",
    "from models.lcnet import Net as LCNet\n",
    "\n",
    "# utils\n",
    "from functions import color_lanes, blend\n",
    "\n",
    "# to cuda or not to cuda\n",
    "if torch.cuda.is_available():\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "    map_location='cpu'\n",
    "map_location='cpu'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1+cu110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptor size definition\n",
    "DESCRIPTOR_SIZE = 64\n",
    "\n",
    "# Maximum number of lanes the network has been trained with + background\n",
    "NUM_CLASSES_SEGMENTATION = 5\n",
    "\n",
    "# Maxmimum number of classes for classification\n",
    "NUM_CLASSES_CLASSIFICATION = 3\n",
    "\n",
    "# Image size\n",
    "HEIGHT = 360\n",
    "WIDTH = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating CNNs and loading pretrained models\n",
    "segmentation_network = ERFNet(NUM_CLASSES_SEGMENTATION)\n",
    "classification_network = LCNet(NUM_CLASSES_CLASSIFICATION, DESCRIPTOR_SIZE, DESCRIPTOR_SIZE)\n",
    "\n",
    "segmentation_network.load_state_dict(torch.load('pretrained/erfnet_tusimple.pth', map_location = map_location))\n",
    "model_path = 'pretrained/classification_{}_{}class.pth'.format(DESCRIPTOR_SIZE, NUM_CLASSES_CLASSIFICATION)\n",
    "classification_network.load_state_dict(torch.load(model_path, map_location = map_location))\n",
    "\n",
    "segmentation_network = segmentation_network.eval()\n",
    "classification_network = classification_network.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    segmentation_network = segmentation_network.cuda()\n",
    "    classification_network = classification_network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('images/test.jpg')\n",
    "img= Image.fromarray(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img):\n",
    "    im = img.resize((WIDTH, HEIGHT))\n",
    "    im_tensor = ToTensor()(im)\n",
    "    im_tensor = im_tensor.unsqueeze(0)\n",
    "    return im,im_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_infer(im_tensor):\n",
    "    # Inference on instance segmentation\n",
    "    if torch.cuda.is_available():\n",
    "        im_tensor = im_tensor.cuda()\n",
    "\n",
    "    out_segmentation = segmentation_network(im_tensor)\n",
    "    out_segmentation = out_segmentation.max(dim=1)[1]\n",
    "    return out_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz(im,out_segmentation):\n",
    "    # Converting to numpy for visualization\n",
    "    out_segmentation_np = out_segmentation.cpu().numpy()[0]\n",
    "    out_segmentation_viz = np.zeros((HEIGHT, WIDTH, 3))\n",
    "\n",
    "    for i in range(1, NUM_CLASSES_SEGMENTATION):\n",
    "        rand_c1 = random.randint(1, 255)\n",
    "        rand_c2 = random.randint(1, 255)    \n",
    "        rand_c3 = random.randint(1, 255)\n",
    "        out_segmentation_viz = color_lanes(\n",
    "            out_segmentation_viz, out_segmentation_np, \n",
    "            i, (rand_c1, rand_c2, rand_c3), HEIGHT, WIDTH)\n",
    "\n",
    "    im_seg = blend(im, out_segmentation_viz)\n",
    "    return im_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im,tensor=read_image(img)\n",
    "im_seg=seg_infer(tensor)\n",
    "im_seg=viz(im,im_seg)\n",
    "imshow(np.asarray(im_seg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('project_video.mp4')\n",
    "\n",
    "#get size to be saved\n",
    "size = (WIDTH,HEIGHT)\n",
    "#fps of video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#video saved format\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter('output_videox.avi', fourcc, fps, size)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "  if ret == True:\n",
    "    img= Image.fromarray(frame)\n",
    "    im,tensor=read_image(img)\n",
    "    im_seg=seg_infer(tensor)\n",
    "    im_seg=viz(im,im_seg)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame',np.array(im_seg))\n",
    "    out.write(np.array(im_seg).astype('uint8'))\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
